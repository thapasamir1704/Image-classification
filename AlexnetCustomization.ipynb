{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thapasamir1704/Image-classification/blob/main/AlexnetCustomization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqBNyU679k_0"
      },
      "source": [
        "#Installing required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzBxp0aZ7uQM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import feature\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import sys\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "%load_ext tensorboard\n",
        "from numpy import asarray\n",
        "import shutil\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import save_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfU4b_ns9ihg"
      },
      "source": [
        "#Mount and unzip the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo-PiraX9wVT"
      },
      "outputs": [],
      "source": [
        "#We mount our google drive to have access to the data files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJdIiKzq9zfE"
      },
      "outputs": [],
      "source": [
        "# Change the directory to the file directory.\n",
        "%cd #filepath                #Change filepath to the filepath you have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG_7Zvej-Lo8"
      },
      "outputs": [],
      "source": [
        "!pwd\n",
        "!unzip dataset.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_0JE1uG-PYJ"
      },
      "source": [
        "#Data preprocessing and splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtrhtLN8gdRr"
      },
      "outputs": [],
      "source": [
        "#This section aims to shuffle files so that it can produce the same output using a random seed.\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Set the directory path to shuffle the files in\n",
        "dir_path = #filepath                #Change filepath to the filepath you have.\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "random.seed(10)\n",
        "\n",
        "# Loop through all subdirectories in the given directory\n",
        "shuffled_filenames_by_dir = {}\n",
        "for sub_dir in os.listdir(dir_path):\n",
        "    sub_dir_path = os.path.join(dir_path, sub_dir)\n",
        "    # Check if the path is a directory\n",
        "    if os.path.isdir(sub_dir_path):\n",
        "        # Get a list of all files in the directory\n",
        "        files = os.listdir(sub_dir_path)\n",
        "        # Shuffle the list of files\n",
        "        random.shuffle(files)\n",
        "        # Create a list of shuffled filenames for the subdirectory\n",
        "        shuffled_filenames_by_dir[sub_dir] = files\n",
        "\n",
        "# Print the shuffled filenames for each subdirectory\n",
        "for sub_dir, shuffled_filenames in shuffled_filenames_by_dir.items():\n",
        "    print(f\"Shuffled filenames for subdirectory '{sub_dir}':\")\n",
        "    print(shuffled_filenames)\n",
        "\n",
        "#The list is to check that the list is shuffled in the same order each time. I have run the code multiple times, and can ensure that the list is the same.\n",
        "#I have also run it in multiple sections instead of running the same code multiple times, and created different lists. The resulting output is the same.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V83Rg2FCjEK"
      },
      "outputs": [],
      "source": [
        "#We use os to get pathname as well as the folder name which we will be using as labels for our classifiers.\n",
        "#Change the folder_path to the actual pathname where we unzipped the dataset.\n",
        "animals = []\n",
        "import os\n",
        "folder_path=#filepath                #Change filepath to the filepath you have.\n",
        "for file in os.listdir(folder_path):\n",
        "    folder = os.path.join(folder_path, file)\n",
        "    if os.path.isdir(folder):\n",
        "        animals.append(os.path.basename(folder))\n",
        "print (animals)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqp32iitR7GD"
      },
      "outputs": [],
      "source": [
        "#This section counts the number of images for each class so that we can ensure the split into train, valid and test is even for every class.\n",
        "path = #filepath                #Change filepath to the filepath you have.\n",
        "def count_files(path):\n",
        "    file_count = 0\n",
        "    dir_count = 0\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for name in files:\n",
        "            file_count += 1\n",
        "        for name in dirs:\n",
        "            dir_count += 1\n",
        "            sub_path = os.path.join(root, name)\n",
        "            sub_files, sub_dirs = count_files(sub_path)\n",
        "            file_count += sub_files\n",
        "            dir_count += sub_dirs\n",
        "    return file_count, dir_count\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    path = #filepath                #Change filepath to the filepath you have.\n",
        "    img_count = {}\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for name in dirs:\n",
        "            sub_path = os.path.join(root, name)\n",
        "            file_count, dir_count = count_files(sub_path)\n",
        "            sub_dir_name = os.path.basename(sub_path) # get the name of the sub-directory\n",
        "            img_count[sub_dir_name] = file_count\n",
        "    print(img_count)\n",
        "    total_images = sum(img_count.values())\n",
        "    print(\"Total Number of Images:\", total_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjTUrs4y-jI4"
      },
      "outputs": [],
      "source": [
        "#We are creating three directories where we will be placing all the images according to the split\n",
        "path = #filepath                #Change filepath to the filepath you have.\n",
        "%cd #filepath                #Change filepath to the filepath you have.\n",
        "%mkdir train\n",
        "%mkdir test\n",
        "%mkdir valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM42k_Or-mz9"
      },
      "outputs": [],
      "source": [
        "#This section moves 20% of images of each class to a test folder.\n",
        "path = #filepath                #Change filepath to the filepath you have.\n",
        "folderCount=0\n",
        "folderName ='a'\n",
        "for folder in os.listdir(path):\n",
        "  for animal in animals:\n",
        "    if animal in folder:\n",
        "      %cd /content/gdrive/MyDrive/42028/Assessment2/Image_Classification/dataset_14341022/test\n",
        "      folderName= animal\n",
        "      folder_path = os.path.join('/filepath/test', folderName) #Change the path to the test folder you have created.\n",
        "      if not os.path.exists(folder_path):\n",
        "        os.mkdir(folderName)\n",
        "      testPath = '/filepath/test' #Change the path to the test folder you have created.\n",
        "      newPath = os.path.join(path,animal)\n",
        "      newTestPath=os.path.join(testPath,animal)\n",
        "      folderCount=0\n",
        "      for filename in os.listdir(newPath):\n",
        "        folderCount+=1\n",
        "        if (folderCount < 0.2 * (img_count[animal])):\n",
        "          shutil.move(os.path.join(newPath,filename), newTestPath)\n",
        "        else:\n",
        "          continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK5UVktkDSfL"
      },
      "outputs": [],
      "source": [
        "#This section moves all the remaining images(80%) to train folder.\n",
        "path = #filepath                #Change filepath to the filepath you have\n",
        "folderName = 'a'\n",
        "for folder in os.listdir(path):\n",
        "  for animal in animals:\n",
        "    if animal in folder:\n",
        "      %cd /filepath/train #Change this path to the train directory you have created\n",
        "      newPath = os.path.join(path,animal)\n",
        "      trainPath = '/filepath/train #Change this path to the train directory you have created.\n",
        "      shutil.move(newPath,trainPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNSKIDIQEdQQ"
      },
      "outputs": [],
      "source": [
        "#This section moves 50% of images from test folder (10% of total images) as well as labels to a valid folder. Now, we have achieved 80-10-10 split.\n",
        "path = '/filepath/test' #Change this to the test folder you have created.\n",
        "folderCount=0\n",
        "folderName ='a'\n",
        "for folder in os.listdir(path):\n",
        "  for animal in animals:\n",
        "    if animal in folder:\n",
        "      %cd /filepath/valid #Change this to the valid filepath you have\n",
        "      folderName= animal\n",
        "      folder_path = os.path.join('/filepath/valid', folderName) ##Change this to the valid filepath you have\n",
        "      if not os.path.exists(folder_path):\n",
        "        os.mkdir(folderName)\n",
        "      validPath = '/filepath/valid' #Change this to the valid filepath you have\n",
        "      newPath = os.path.join(path,animal)\n",
        "      newValidPath=os.path.join(validPath,animal)\n",
        "      folderCount=0\n",
        "      for filename in os.listdir(newPath):\n",
        "        folderCount+=1\n",
        "        if (folderCount < 0.1 * (img_count[animal])):\n",
        "          shutil.move(os.path.join(newPath,filename), newValidPath)\n",
        "        else:\n",
        "          continue"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This section will display three random images with their labels from the train directory.\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_random_images_from_directory(directory, num_images=3):\n",
        "    image_files = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_files.append(os.path.join(root, file))\n",
        "\n",
        "    random_images = random.sample(image_files, min(num_images, len(image_files)))\n",
        "\n",
        "    for image_path in random_images:\n",
        "        image = plt.imread(image_path)\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        plt.imshow(image)\n",
        "        plt.title(label)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    directory_path = '/filepath/train'  # Replace with the path to the directory containing the images\n",
        "    display_random_images_from_directory(directory_path)\n"
      ],
      "metadata": {
        "id": "NsRcADlaMcoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAj118zqL18W"
      },
      "source": [
        "#Creating Base Alex-net architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aFHK8SHL1hN"
      },
      "outputs": [],
      "source": [
        "model_base = tf.keras.models.Sequential([\n",
        "    #Conv_1          #original model was built for input shape of 224X224\n",
        "    tf.keras.layers.Conv2D(96, (11,11),strides=4, padding='valid', activation='relu', input_shape=(224, 224, 3)),\n",
        "    # Pooling_1\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2),padding='valid'),\n",
        "    # Batch Normalisation_1\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_2\n",
        "    tf.keras.layers.Conv2D(256, (11,11),strides=1, padding='valid', activation='relu'),\n",
        "    # Pooling_2\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2),padding='valid'),\n",
        "    #Batch Normalisation_2\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_3\n",
        "    tf.keras.layers.Conv2D(384, (3,3),strides=1, padding='valid', activation='relu'),\n",
        "    # Batch Normalisation_3\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_4\n",
        "    tf.keras.layers.Conv2D(384, (3,3),strides=1, padding='valid', activation='relu'),\n",
        "    # Batch Normalisation_4\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #conv_5\n",
        "    tf.keras.layers.Conv2D(256, (3,3),strides=1, padding='valid', activation='relu'),\n",
        "    #pooling_3\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2),padding='valid'),\n",
        "    #Batch Normalization_5\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #Dense layer_1\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Dense layer_2\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Dense layer_3\n",
        "    tf.keras.layers.Dense(1000, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(20, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL2YhfCNNR02"
      },
      "outputs": [],
      "source": [
        "# Perform image augmentation and create data generators\n",
        "train_dir = '/filepath/train' #Change this path to the train folder you have.\n",
        "valid_dir = '/filepath/valid' #Change this path to the validation folder you have.\n",
        "test_dir =  '/filepath/test' #Change this path to the test folder you have.\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest',\n",
        "      )\n",
        "valid_datagen = ImageDataGenerator (rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_s =32\n",
        "\n",
        "\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_dir,\n",
        "          #Write code here#,  # This is the source directory for training images\n",
        "  target_size = (224, 224), #Write code here#),  ]\n",
        "  batch_size=batch_s,\n",
        "          # Since we use binary_crossentropy loss, we need binary labels\n",
        "  class_mode='categorical')\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "  valid_dir,\n",
        "          #Write code here#,  # This is the source directory for training images\n",
        "  target_size = (224, 224), #Write code here#),\n",
        "  batch_size=batch_s,\n",
        "          # Since we use binary_crossentropy loss, we need binary labels\n",
        "  class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "  test_dir,\n",
        "        target_size=(224,224), #Write code here\n",
        "        batch_size=batch_s,\n",
        "        class_mode= 'categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb_MccL3QBB4"
      },
      "outputs": [],
      "source": [
        "#Compiling the model\n",
        "model_base.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display Model Summary\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import HTML, display, clear_output, SVG\n",
        "model_base.summary()\n",
        "\n",
        "# Save model architecture as an image file\n",
        "plot_model(model_base, to_file='model.png', show_layer_names=True, show_shapes=True, rankdir='LR')\n",
        "\n",
        "# Display model architecture inline in Jupyter Notebook\n",
        "SVG(model_to_dot(model_base, show_layer_names=True, show_shapes=True, rankdir='LR').create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "id": "wRIh_FzaazlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wltqp4LWQInV"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model_base.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.n//batch_s,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.n//batch_s,\n",
        "      verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xijSP9t6t8p2"
      },
      "outputs": [],
      "source": [
        "#Evaluating it on test data\n",
        "model_base.evaluate_generator(test_generator)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0P2YroZvvdw"
      },
      "outputs": [],
      "source": [
        "#Evaluation on validation data\n",
        "model_base.evaluate_generator(validation_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkyiCoE2t--u"
      },
      "outputs": [],
      "source": [
        "#Save the created model\n",
        "#Change the name to suit your need\n",
        "save_model(model_base, 'model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVuo-utnuC7_"
      },
      "outputs": [],
      "source": [
        "#Plot training and validation accuracy and loss\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wh4PO3y4MLN"
      },
      "outputs": [],
      "source": [
        "#This section aims to provide examples of images with their predicted labels and original labels.\n",
        "\n",
        "# Make predictions on the test data using the trained model\n",
        "predictions = model_base.predict(test_generator)\n",
        "\n",
        "# Get the class labels corresponding to the predicted probabilities\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the original class labels from the test generator\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "# Get the class names from the test generator\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Get a batch of test images and their corresponding labels\n",
        "images, _ = test_generator.next()\n",
        "\n",
        "# Plot the images with their original and predicted labels\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(f\"True: {class_names[true_labels[i]]}\\nPredicted: {class_names[predicted_labels[i]]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa5ZhuEd2POu"
      },
      "source": [
        "#FINAL CUSTOMIZED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VltW_F69LEFx"
      },
      "outputs": [],
      "source": [
        "\n",
        "#In this model, 2 convolution layers (layer 4 and 5) are removed. The convolution layer 3 is resized to 256 nodes from previous 384 nodes.\n",
        "#Regularizer is used in the last 2 convolution layers (except the input layer).\n",
        "regularizer = tf.keras.regularizers.l2(0.1)\n",
        "model_custom = tf.keras.models.Sequential([\n",
        "    # Conv_1\n",
        "    tf.keras.layers.Conv2D(96, (11, 11), strides=4, padding='valid', activation='relu', input_shape=(224, 224, 3)),\n",
        "    # Pooling_1\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_1\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_2\n",
        "    tf.keras.layers.Conv2D(256, (5, 5), strides=1, padding='same', activation='relu', kernel_regularizer=regularizer),\n",
        "    # Pooling_2\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_2\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_3\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', kernel_regularizer=regularizer),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Removed Conv_4\n",
        "    #tf.keras.layers.Conv2D(256, (3,3),strides=1, padding='valid', activation='relu'),\n",
        "     #Batch Normalisation_4\n",
        "    #tf.keras.layers.BatchNormalization(),\n",
        "    #  Removed Conv_5\n",
        "   # tf.keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', kernel_regularizer=regularizer),\n",
        "    #tf.keras.layers.BatchNormalization(),\n",
        "    # Pooling_3\n",
        "    #tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_3\n",
        "    #tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # Dense layer_1\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # Batch Normalization_4\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Dense layer_2\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # Batch Normalization_5\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Dense layer 3\n",
        "    tf.keras.layers.Dense(1000, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # Batch Normalization_5\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(20, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld_PWa_Q22Xq"
      },
      "outputs": [],
      "source": [
        "# Perform image augmentation and create data generators\n",
        "train_dir = '/filepath/train' #Change this path to the train folder you have.\n",
        "valid_dir = '/filepath/valid' #Change this path to the validation folder you have.\n",
        "test_dir =  '/filepath/test' #Change this path to the test folder you have.\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest',\n",
        "      )\n",
        "valid_datagen = ImageDataGenerator (rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_s =32\n",
        "\n",
        "\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_dir,\n",
        "          #Write code here#,  # This is the source directory for training images\n",
        "  target_size = (224, 224), #Write code here#),  ]\n",
        "  batch_size=batch_s,\n",
        "          # Since we use binary_crossentropy loss, we need binary labels\n",
        "  class_mode='categorical')\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "  valid_dir,\n",
        "          #Write code here#,  # This is the source directory for training images\n",
        "  target_size = (224, 224), #Write code here#),\n",
        "  batch_size=batch_s,\n",
        "          # Since we use binary_crossentropy loss, we need binary labels\n",
        "  class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "  test_dir,\n",
        "        target_size=(224,224), #Write code here\n",
        "        batch_size=batch_s,\n",
        "        class_mode= 'categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnymQ7_ZGFt6"
      },
      "outputs": [],
      "source": [
        "#This section complies the customized model\n",
        "model_custom.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ_8T58uXFMk"
      },
      "outputs": [],
      "source": [
        "#Display Model Summary\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import HTML, display, clear_output, SVG\n",
        "model_custom.summary()\n",
        "\n",
        "# Save model architecture as an image file\n",
        "plot_model(model_custom, to_file='model.png', show_layer_names=True, show_shapes=True, rankdir='LR')\n",
        "\n",
        "# Display model architecture inline in Jupyter Notebook\n",
        "SVG(model_to_dot(model_custom, show_layer_names=True, show_shapes=True, rankdir='TB').create(prog='dot', format='svg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1fiFvf3GSVu"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history_custom = model_custom.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.n//batch_s,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.n//batch_s,\n",
        "      verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgz6ldfkoRrg"
      },
      "outputs": [],
      "source": [
        "#I have used regularization on three dense layers. The train arraucy is 0.8424 and test accuracy is 0.4896. The model is severely overfitting and performing worse than before.\n",
        "#I had removed one convolution layer. Now, I will remove one dense layer to  see if it improves.\n",
        "#After I did regularization on two dense layers, the train accuracy rose up to 0.8757 with a loss of 1.7030. However, the validation accuracy was 0.6840 with a loss of 2.8073.  .\n",
        "#The test accuracy was around 0.657 with a loss of 2.91. It performed better than the previous regularization model, but the model is still overfitting and the accuracy is\n",
        "#the same as baseline model.\n",
        "#I will now try to use regularization on convolution layer to see if it makes a difference. I have added regularization to two layers which has the highest number of nodes to see if\n",
        "#it makes a difference.\n",
        "#I noticed that the model I made after the base model performed better, so I am customizing it further before doing regularization.\n",
        "\n",
        "#Then, I removed convolution 4 and last dense layer, and applied regularization with value 0.05 on last 2 convolution layers (3 and 5). The train accuracy was 0.8129 with a loss of 0.8480\n",
        "#The validation acc was 0.6215 with a alos of 2.0903. The test acc was 0.567 with a loss of 2.49. The model is still overfitting. Now I am gonna experiment value of 0.1\n",
        "#wHEN i USED REGULARIZATION value of 01, the train accuracy was 0.7847 with a loss of 0.9571 and validation accuracy was 0.6562 with a loss of 1.6501. The test accuracy was 0.6168 with a loss of 1.747. The model is still overfitting.\n",
        "\n",
        "#Now, I will put back the dense layer I removed, remove the last 2 convolution layers and put the regularizer on last two convolution layers.\n",
        "#I removed the last 2 convolution layers, and applied regularization on the other  two convolution layers. The initial train accuracy is 0..7388 with a loss of 1.0906, the validation accuracy is 0.6424 with a loss of 1.6521.\n",
        "#The test accuracy was 0.61999 with a loss of 1.6966\n",
        "#Now, I am going to change the last convolution layer to be with 256 nodes instead of previous 358.\n",
        "#The test accuracy is the same 0.6199 with a loss of 1.6968."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC5pSVsMb9pd"
      },
      "outputs": [],
      "source": [
        "#Performance on test data\n",
        "model_custom.evaluate_generator(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Performance on train data\n",
        "model_custom.evaluate_generator(train_generator)"
      ],
      "metadata": {
        "id": "9BH2kimgF56Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performance on validation data\n",
        "model_custom.evaluate_generator(validation_generator)"
      ],
      "metadata": {
        "id": "zVe-oQCAF8sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyhFfM7ZgC6S"
      },
      "outputs": [],
      "source": [
        "#Plots training and validation loss and acccuracy for the customized model\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history_custom.history['acc']\n",
        "val_acc =  history_custom.history['val_acc']\n",
        "loss =  history_custom.history['loss']\n",
        "val_loss =  history_custom.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCZoEv2VoTVL"
      },
      "outputs": [],
      "source": [
        "#This section aims to provide examples of images with their predicted labels and original labels.\n",
        "\n",
        "# Make predictions on the test data using the trained model\n",
        "predictions = model_custom.predict(test_generator)\n",
        "\n",
        "# Get the class labels corresponding to the predicted probabilities\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the original class labels from the test generator\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "# Get the class names from the test generator\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Get a batch of test images and their corresponding labels\n",
        "images, _ = test_generator.next()\n",
        "\n",
        "# Plot the images with their original and predicted labels\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(f\"True: {class_names[true_labels[i]]}\\nPredicted: {class_names[predicted_labels[i]]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V77aebzeIgRE"
      },
      "source": [
        "# Other Customized Models\n",
        "These are other models that were used for the experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ngsAkRu1_Yw"
      },
      "source": [
        "Model 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z5RY0R7IiR4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model2 = tf.keras.models.Sequential([\n",
        "    # Conv_1\n",
        "    tf.keras.layers.Conv2D(96, (11, 11), strides=4, padding='valid', activation='relu', input_shape=(224, 224, 3)),\n",
        "    # Pooling_1\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_1\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Conv_2\n",
        "    tf.keras.layers.Conv2D(256, (5, 5), strides=1, padding='same', activation='relu'),\n",
        "    # Pooling_2\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_2\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Conv_3\n",
        "    tf.keras.layers.Conv2D(384, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_4\n",
        "    tf.keras.layers.Conv2D(384, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_5\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Pooling_3\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_3\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Dense layer_1\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # Batch Normalization_4\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Dense layer_2\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # Batch Normalization_5\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Dense layer_3\n",
        "    tf.keras.layers.Dense(20, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAST0DtPL4K2"
      },
      "outputs": [],
      "source": [
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOyl4nfDL9TB"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history2 = model2.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.n//batch_s,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.n//batch_s,\n",
        "      verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujUT1Ask0bsS"
      },
      "outputs": [],
      "source": [
        "model2.evaluate_generator(test_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRWj8zXl0w3A"
      },
      "outputs": [],
      "source": [
        "save_model(model2, 'model2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B-JJ-f-0mIV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history2.history['acc']\n",
        "val_acc = history2.history['val_acc']\n",
        "loss = history2.history['loss']\n",
        "val_loss = history2.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVJTFj-9gqB8"
      },
      "source": [
        "Model 4:\n",
        "Removing one convolution layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE_EDHJV19lt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model3 = tf.keras.models.Sequential([\n",
        "    # Conv_1\n",
        "    tf.keras.layers.Conv2D(96, (11, 11), strides=4, padding='valid', activation='relu', input_shape=(224, 224, 3)),\n",
        "    # Pooling_1\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_1\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Conv_2\n",
        "    tf.keras.layers.Conv2D(256, (5, 5), strides=1, padding='same', activation='relu'),\n",
        "    # Pooling_2\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_2\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Conv_3\n",
        "    tf.keras.layers.Conv2D(384, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_4\n",
        "    tf.keras.layers.Conv2D(384, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Removed conv_5\n",
        "    # Pooling_3\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
        "    # Batch Normalization_3\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Dense layer_1\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # Batch Normalization_4\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Dense layer_2\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # Batch Normalization_5\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Dense layer_3\n",
        "    tf.keras.layers.Dense(20, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQhsIClu4Sox"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z6FE-tS5Xek"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history3 = model3.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.n//batch_s,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.n//batch_s,\n",
        "      verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA6noZTDIRFQ"
      },
      "outputs": [],
      "source": [
        "model3.evaluate_generator(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-2KjAy5Iseb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history3.history['acc']\n",
        "val_acc = history3.history['val_acc']\n",
        "loss = history3.history['loss']\n",
        "val_loss = history3.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCHN1DpY2O3o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPtx7h7VCktNR4rxdfAaU3D",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}