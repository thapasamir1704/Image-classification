{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRqEWM1mvE2L1k//EdN5ck"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SfFWCVUmG3SR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we import the required packages for this task."
      ],
      "metadata": {
        "id": "iqiG_X9KDvFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Required Packages"
      ],
      "metadata": {
        "id": "l6jTzCmpGwop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN05LXZqeESY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import feature # This pacakge is used for LBP feature extraction\n",
        "from sklearn import svm # This pacakge is used for svm classification\n",
        "from sklearn import metrics\n",
        "import sys\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import seaborn as sns # This pacakge is used for better visualization of data (e.g confusion matrix)\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mouting the drive and unzip the dataset"
      ],
      "metadata": {
        "id": "sbLdJ22oJsK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#We mount our google drive to have access to the data files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "sVe4hP-8gd8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the directory\n",
        "%cd #filepath                #Change filepath to the filepath you have.\n"
      ],
      "metadata": {
        "id": "dfR0jxHugfmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip the dataset\n",
        "!pwd\n",
        "!unzip dataset.zip\n"
      ],
      "metadata": {
        "id": "P4cNyvDBJzS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Getting Symbol Names\n"
      ],
      "metadata": {
        "id": "cBgPtGuxHBll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We use os to get pathname as well as the folder name which we will be using as labels for our classifiers.\n",
        "symbols = []\n",
        "import os\n",
        "folder_path=#filepath                #Change filepath to the filepath you have.\n",
        "for file in os.listdir(folder_path):\n",
        "    folder = os.path.join(folder_path, file)\n",
        "    if os.path.isdir(folder):\n",
        "        symbols.append(os.path.basename(folder))\n",
        "print (symbols)\n",
        "\n"
      ],
      "metadata": {
        "id": "Pn50UynDhXu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plase refer to the section below if you have trouble getting folder names with the section above."
      ],
      "metadata": {
        "id": "x8atlmGgrtWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Alternatively, we can use keras to train a small model and retrieve class names from the trained model.\n",
        "#This section of the code will create a training set, which will not be used later. Only the class labels created from the data set will be used.\n",
        "# use this section in case you are unable to get the folder names from the section above.\n",
        "\n",
        "#train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        " # '/content/gdrive/My Drive/42028/Assessment1/',\n",
        " # validation_split=0.2,\n",
        " # subset=\"training\",\n",
        " # seed=123,\n",
        " # image_size=(256, 256),\n",
        " # batch_size=32)\n",
        "\n",
        "#symbols = train_ds.class_names\n",
        "#print(symbols)"
      ],
      "metadata": {
        "id": "MNMUF04qmbP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image retrieval"
      ],
      "metadata": {
        "id": "2MFGlaO_NeZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This section of the program will retrieve inidiviual images from all the folders into the variable 'data'.\n",
        "path_actual=#filepath                #Change filepath to the filepath you have.\n",
        "def getData():\n",
        "  import os\n",
        "  data = []\n",
        "  count = 0\n",
        "  for folder in os.listdir (path_actual):\n",
        "      for symbol in symbols:\n",
        "        if symbol in folder:\n",
        "          symbol_class = symbols.index(symbol)\n",
        "          path= os.path.join (path_actual,symbol)\n",
        "          for filename in os.listdir(path):\n",
        "            count+=1\n",
        "            image = cv2.imread(os.path.join(path,filename),cv2.IMREAD_GRAYSCALE)\n",
        "            data.append([image,symbol_class])\n",
        "  print(count)\n",
        "  return data"
      ],
      "metadata": {
        "id": "7ZilBgHRgh1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting data into Training and Test set"
      ],
      "metadata": {
        "id": "KPUW6b2oNc9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This section of the code will be used for splitting the data set between training set and test set. Since the dataset has a total of 5000 images.\n",
        "#70% will be used for training and 30% for testing. The code ensures that the 70% images used for training will be proportionate across all classes.\n",
        "#x_train and y_train are the training data and labels respectively, and x_test and y_test are test data and labels respectively. Each class contains 500 images\n",
        "def split_dataset (dataset):\n",
        "\n",
        "  x_train =[]\n",
        "  y_train =[]\n",
        "  x_test=[]\n",
        "  y_test=[]\n",
        "  test_dataset= []\n",
        "  for image,label in dataset:\n",
        "      if y_train.count(label)<0.7*500:\n",
        "        x_train.append(image)\n",
        "        y_train.append(label)\n",
        "      else:\n",
        "        test_dataset.append([image,label])\n",
        "  for image,label in test_dataset:\n",
        "      x_test.append(image)\n",
        "      y_test.append(label)\n",
        "\n",
        "\n",
        "  return x_train,y_train,x_test,y_test"
      ],
      "metadata": {
        "id": "A6yr1zt8hhsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We are initializing 'Data1' to call the getData() function we created above.\n",
        "Data_SVM= getData()\n",
        "\n"
      ],
      "metadata": {
        "id": "Q7U7j8JgkH5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We are using the split_dataset  function with the 'Data1' object we created above which will return our training and testing parameters.\n",
        "x_train, y_train, x_test, y_test = split_dataset(Data_SVM)\n",
        "print (len(x_train))\n",
        "print(np.shape(x_train))"
      ],
      "metadata": {
        "id": "wWxI-phbl9uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization\n"
      ],
      "metadata": {
        "id": "zBqD8lQ2HLTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view few images and print its corresponding label\n",
        "img_index = 10\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2,5,1)\n",
        "ax1.axis('off')\n",
        "ax1.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,2)\n",
        "ax2.axis('off')\n",
        "img_index = 360\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,3)\n",
        "ax2.axis('off')\n",
        "img_index = 750\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,4)\n",
        "ax2.axis('off')\n",
        "img_index = 1100\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,5)\n",
        "ax2.axis('off')\n",
        "img_index = 1600\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,6)\n",
        "ax2.axis('off')\n",
        "img_index = 1800\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,7)\n",
        "ax2.axis('off')\n",
        "img_index = 2100\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,8)\n",
        "ax2.axis('off')\n",
        "img_index = 2700\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,9)\n",
        "ax2.axis('off')\n",
        "img_index = 3000\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,5,10)\n",
        "ax2.axis('off')\n",
        "img_index = 3400\n",
        "ax2.imshow(x_train[img_index])\n",
        "print(symbols[y_train[img_index]])\n"
      ],
      "metadata": {
        "id": "AaIHDSLOm9Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Displaying the shape of raw images\n",
        "print (np.shape(x_train))\n",
        "print (np.shape(x_test))\n",
        "print (np.shape(y_train))\n",
        "print (np.shape(y_test))\n"
      ],
      "metadata": {
        "id": "eqR2QOEu618_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 1: Raw images preprocessing"
      ],
      "metadata": {
        "id": "_O5rzpzQOEY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating arrays of training and testing images and labels to be used for raw model.\n",
        "x_train_raw = np.array(x_train)\n",
        "x_test_raw = np.array(x_test)\n",
        "y_train_raw = np.array(y_train)\n",
        "y_test_raw = np.array(y_test)"
      ],
      "metadata": {
        "id": "I0JMNqPwK1CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(x_train_raw))"
      ],
      "metadata": {
        "id": "IafzPjHmLCdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the images into one dimensional array to feed into the model\n",
        "x_train_raw = x_train_raw.reshape(len(x_train_raw),-1)\n",
        "x_test_raw= x_test_raw.reshape(len(x_test_raw),-1)"
      ],
      "metadata": {
        "id": "u-IAOsvE87bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training SVM for raw images"
      ],
      "metadata": {
        "id": "SOno8XryOSAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a SVM clasifier on the training data\n",
        "# Initialize the SVM model\n",
        "# Use rbf Kernel, c = 100 and randon_state=42\n",
        "#using c=100.0 gives us the test accuracy of 0.9785, and using c=50.0 gives the test accuracy of 0.985\n",
        "#Using c=25.0 has the same accuracy value as c=50\n",
        "#Since the subsequent modesl will be using c=100 as it is proven to have higher accuracy for LBP and HOG, c=100 will be used to ensure consistency.\n",
        "\n",
        "\n",
        "model_SVM_RAW = svm.SVC(kernel='rbf', C=100.0, random_state=42)\n",
        "\n",
        "# Start training the SVM classifier\n",
        "model_SVM_RAW.fit(x_train_raw, y_train_raw)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ARG-nZFu7MLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the training accuray\n",
        "print(\"Train set Accuracy: {:.2f}\".format(model_SVM_RAW.score(x_train_raw,y_train_raw)))"
      ],
      "metadata": {
        "id": "zqB_Y9fr9s4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing SVM with raw images on test data set"
      ],
      "metadata": {
        "id": "m4KyFOtCOb-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating on Test dataset\n",
        "raw_predictions=[]\n",
        "raw_predict_label=[]\n",
        "# Exract LBP features for each test sample and classify it with the trained SVM classifier\n",
        "\n",
        "\n",
        "for img_index in range(len(x_test_raw)):\n",
        "  imag = x_test_raw[img_index]\n",
        "  # Perform classification, Hint: use model.predict()\n",
        "  prediction = model_SVM_RAW.predict(imag.reshape(1,-1))\n",
        "\n",
        "\n",
        "  # Store the classfication result\n",
        "  raw_predictions.append(prediction)\n",
        "  raw_predict_label.append(y_test[img_index])"
      ],
      "metadata": {
        "id": "HEM19f3F-a4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy and confusion matrix for test data set for raw pixels"
      ],
      "metadata": {
        "id": "Kf7ZR7aPOmAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.accuracy_score(y_test_raw, raw_predictions)\n",
        "print(\"Accuracy on test dataset:\",accuracy)"
      ],
      "metadata": {
        "id": "udOLdcmy_WEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the confusion matrix\n",
        "cm_raw  = metrics.confusion_matrix(y_test_raw, raw_predictions)\n",
        "print(cm_raw)\n",
        "\n",
        "# Plot confusion matrix using seaborn library\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm_raw, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(accuracy)\n",
        "plt.title(all_sample_title, size = 15);"
      ],
      "metadata": {
        "id": "3cr4B9QK_amL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will randomly grab a few images and their classifications.\n",
        "images_raw=[]\n",
        "raw_orig_label = []\n",
        "for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n",
        "  # classify the images\n",
        "  image_raw = x_test_raw[i]\n",
        "  prediction = model_SVM_RAW.predict(image_raw.reshape(1, -1))\n",
        "  label = symbols[prediction[0]]\n",
        "  raw_orig_label=symbols[y_test[i]]\n",
        "  image= x_test[i]\n",
        "  color = (0, 255, 0)\n",
        "  image= cv2.merge([image] * 3)\n",
        "  image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "  cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50,color, 2)\n",
        "  images_raw.append(image)\n",
        "\n"
      ],
      "metadata": {
        "id": "Aksh7d7s_sx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Display the classification results\n",
        "#Plot the image and the predicted labels\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax1.imshow(images_raw[0])\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "ax2.imshow(images_raw[1])\n",
        "ax3 = fig.add_subplot(2,2,3)\n",
        "ax3.imshow(images_raw[2])\n",
        "ax4 = fig.add_subplot(2,2,4)\n",
        "ax4.imshow(images_raw[3])"
      ],
      "metadata": {
        "id": "5hDn9rxnAeQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Section 2:LBP Class Definition for SVM"
      ],
      "metadata": {
        "id": "dy8Yvhq5HSsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LBP CLASS DEFINITION\n",
        "class LocalBinaryPatterns:\n",
        "\tdef __init__(self, points, radius):\n",
        "\t\t# store the number of points and radius\n",
        "\t\tself.points = points\n",
        "\t\tself.radius = radius\n",
        "\n",
        "\tdef LBPfeatures(self, image, eps=1e-7):\n",
        "\t\t# compute the Local Binary Pattern representation\n",
        "\t\t# of the image, and then use the LBP representation\n",
        "\t\t# to build the histogram of patterns\n",
        "\t\tlbp = feature.local_binary_pattern(image, self.points,\n",
        "\t\t\tself.radius, method=\"uniform\")\n",
        "    # Form the histogram\n",
        "\t\t(hist, _) = np.histogram(lbp.ravel(),\n",
        "\t\t\tbins=np.arange(0, self.points + 3),\n",
        "\t\t\trange=(0, self.points + 2))\n",
        "\n",
        "\t\t# normalize the histogram\n",
        "\t\thst = hist.astype(\"float\")\n",
        "\t\thst /= (hist.sum() + eps)\n",
        "\n",
        "\t\t# return the histogram of Local Binary Patterns\n",
        "\t\treturn hst"
      ],
      "metadata": {
        "id": "z_9A8WjRngMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an object of LocalBinaryPatterns class and initial the parameters.\n",
        "desc = LocalBinaryPatterns(24, 8)\n",
        "data_train = []\n",
        "labels_train = []\n",
        "\n",
        "\n",
        "# loop over the training images\n",
        "for img_index in range(len(x_train)):\n",
        "\t# load the train image, and extract LBP features\n",
        "\timage = (x_train [img_index])\n",
        "\thist = desc.LBPfeatures (image)\n",
        "\n",
        "\n",
        "\t# extract the label from the image path, then update the\n",
        "\t# label and data lists\n",
        "\tlabels_train.append(y_train[img_index])\n",
        "\tdata_train.append(hist)"
      ],
      "metadata": {
        "id": "XZXKPJRLn05C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Creating SVM model with LBP feature extraction\n",
        "\n"
      ],
      "metadata": {
        "id": "2-wePjG2H1M2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a SVM clasifier on the training data\n",
        "# Initialize the SVM model\n",
        "# Use rbf Kernel, c = 100 and randon_state=42\n",
        "#using the value of c=50 has an accuracy of 0.75 whereas the value c=100 has accuracy of 0.78\n",
        "\n",
        "model = svm.SVC(kernel='rbf', C=100.0, random_state=42)\n",
        "# Start training the SVM classifier\n",
        "model.fit(data_train, labels_train)\n",
        "\n",
        "\n",
        "print(np.shape(data_train))\n",
        "print(np.shape(labels_train))"
      ],
      "metadata": {
        "id": "HABzWVKtnsVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the training accuray\n",
        "print(\"Train set Accuracy: {:.2f}\".format(model.score(data_train,labels_train)))\n"
      ],
      "metadata": {
        "id": "MGeTwUNjo0OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on Test dataset after LBP feature extraction\n"
      ],
      "metadata": {
        "id": "FXgrutrNPw2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating on Test dataset\n",
        "predictions=[]\n",
        "predict_label=[]\n",
        "# Exract LBP features for each test sample and classify it with the trained SVM classifier\n",
        "\n",
        "\n",
        "for img_index in range(len(x_test)):\n",
        "  imag = x_test[img_index]\n",
        "\n",
        "  # Extract LBP feature\n",
        "  histo = desc.LBPfeatures (imag)\n",
        "  # Perform classification, Hint: use model.predict()\n",
        "  prediction = model.predict(histo.reshape(1,-1))\n",
        "\n",
        "\n",
        "  # Store the classfication result\n",
        "  predictions.append(prediction)\n",
        "  predict_label.append(y_test[img_index])"
      ],
      "metadata": {
        "id": "aX11Saeco040"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy and evaluation of SVM with LBP extraction"
      ],
      "metadata": {
        "id": "jdl3CVgoK25E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy on test dataset:\",accuracy)\n",
        "# plot the confusion matrix\n",
        "cm  = metrics.confusion_matrix(y_test, predictions)\n",
        "print(cm)\n",
        "\n",
        "# Plot confusion matrix using seaborn library\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(accuracy)\n",
        "plt.title(all_sample_title, size = 15);"
      ],
      "metadata": {
        "id": "vc4qJOKrpVYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Showing some classification results from the SVM model"
      ],
      "metadata": {
        "id": "Ery3HtpjLByf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some classification result on test samples\n",
        "images = []\n",
        "LBP_orig_label = []\n",
        "# randomly select a few testing fashion items\n",
        "for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n",
        "  # classify the clothing\n",
        "  histog = desc.LBPfeatures(x_test[i])\n",
        "  prediction = model.predict(histog.reshape(1, -1))\n",
        "  label = symbols[prediction[0]]\n",
        "  LBP_orig_label=symbols[y_test[i]]\n",
        "  image = x_test[i]\n",
        "  color = (0, 255, 0)\n",
        "  image = cv2.merge([image] * 3)\n",
        "  image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "  cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50, color, 2)\n",
        "  images.append(image)"
      ],
      "metadata": {
        "id": "arErMrknLISO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(images[1])"
      ],
      "metadata": {
        "id": "wlvR1cSILZ51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Display the classification results\n",
        "#Plot the image and the predicted labels\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax1.imshow(images[1])\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "ax2.imshow(images[2])\n",
        "ax3 = fig.add_subplot(2,2,3)\n",
        "ax3.imshow(images[5])\n",
        "ax4 = fig.add_subplot(2,2,4)\n",
        "ax4.imshow(images[6])"
      ],
      "metadata": {
        "id": "S0SMs4x7Lder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  HOG feature extraction for SVM\n"
      ],
      "metadata": {
        "id": "6H9L6TI7IRct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HOG feature extraction\n",
        "# initialize the data matrix and labels\n",
        "print(\"Extracting features from training dataset...\")\n",
        "datahog_train = []\n",
        "labelshog_train = []\n",
        "\n",
        "# loop over the training images\n",
        "for imge_index in range(len(x_train)):\n",
        "  # load the image, and extract HOG features it\n",
        "\n",
        "  image = (x_train [imge_index])\n",
        "  H = feature.hog(image, orientations=9, pixels_per_cell=(10,10), cells_per_block=(2,2), transform_sqrt=True, block_norm=\"L2-Hys\") # Complete the code\n",
        "\n",
        "  # update the data and labels\n",
        "  datahog_train.append(H)\n",
        "  labelshog_train.append(y_train[imge_index])\n",
        "\n",
        "print(np.shape(datahog_train))\n",
        "print(np.shape(labelshog_train))"
      ],
      "metadata": {
        "id": "QoJSsYuOpVet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "# Creating SVM model with HOG feature extraction"
      ],
      "metadata": {
        "id": "Y7rknKmUJrPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating another model which uses the features extracting with HOG.\n",
        "# train a SVM clasifier on the training data\n",
        "# Initialize the SVM model\n",
        "# Use rbf Kernel, c = 100 and randon_state=42\n",
        "\n",
        "model2 = svm.SVC(kernel='rbf', C=100.0, random_state=42)  #using the same parameters we used with LBP\n",
        "#Start training the SVM classifier\n",
        "model2.fit(datahog_train, labelshog_train)"
      ],
      "metadata": {
        "id": "yQrTZQ9fqxH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the accuracy of the XVM model we created.\n",
        "\n",
        "print(np.shape(data_train))\n",
        "print(np.shape(labels_train))\n",
        "print(\"Train set Accuracy: {:.2f}\".format(model2.score(datahog_train,labelshog_train)))"
      ],
      "metadata": {
        "id": "8fRLKSObq-M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation and accuracy of SVM with HOG extraction"
      ],
      "metadata": {
        "id": "GEBLJskYQavF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating on a test data set\n",
        "predicthog_test = []\n",
        "labelshog_test = []\n",
        "datahog_test=[]\n",
        "# loop over the training images\n",
        "for img_ind in range(len(x_test)):\n",
        "  # load the image, and extract HOG features\n",
        "  img= x_test[img_ind]\n",
        "  H = feature.hog(img, orientations=9, pixels_per_cell=(10,10), cells_per_block=(2,2), transform_sqrt=True, block_norm=\"L2-Hys\")# Hint: use same settings as used in training phase\n",
        "\n",
        "  pred = model2.predict(H.reshape(1,-1)) [0]\n",
        "  # update the data and labels\n",
        "  predicthog_test.append(pred)\n",
        "  datahog_test.append(H)\n",
        "\n",
        "  labelshog_test.append(y_test[img_ind])\n",
        "\n",
        "print(np.shape(predicthog_test))\n",
        "print(np.shape(labelshog_test))"
      ],
      "metadata": {
        "id": "FehRQt43q-4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set Accuracy\n",
        "\n",
        "accuracy = metrics.accuracy_score(y_test, predicthog_test)\n",
        "print(\"Accuracy on test dataset:\",accuracy)\n",
        "\n",
        "# plot the confusion matrix\n",
        "cm2  = metrics.confusion_matrix(y_test, predictions)\n",
        "print(cm2)\n",
        "\n",
        "# Plot confusion matrix using seaborn library\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm2, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(accuracy)\n",
        "plt.title(all_sample_title, size = 15);\n"
      ],
      "metadata": {
        "id": "HQuBdU21r-VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Showing some classification results from the SVM model\n"
      ],
      "metadata": {
        "id": "Dsd1slV5MYgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "orig_labels=[]\n",
        "# randomly select a few symols\n",
        "for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n",
        "  # classify the images\n",
        "  test_img = (x_test[i])\n",
        "  H1 = feature.hog(test_img, orientations=9, pixels_per_cell=(10, 10),\n",
        "                  cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2-Hys\")\n",
        "  pred = model2.predict(H1.reshape(1, -1))[0]\n",
        "  label = symbols[pred]\n",
        "  orig_labels.append(symbols[y_test[i]])\n",
        "  color = (0, 255, 0)\n",
        "  test_img = cv2.merge([test_img] * 3)\n",
        "  test_img = cv2.resize(test_img, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "  cv2.putText(test_img, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50, color, 2)\n",
        "  images.append(test_img)"
      ],
      "metadata": {
        "id": "ORzusuFTMdwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_labels[1]"
      ],
      "metadata": {
        "id": "xzrX_25SNyoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Display the classification results\n",
        "#Plot the image and the predicted labels\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax1.imshow(images[1])\n",
        "print(orig_labels[1])\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "ax2.imshow(images[2])\n",
        "print(orig_labels[2])\n",
        "ax3 = fig.add_subplot(2,2,3)\n",
        "ax3.imshow(images[3])\n",
        "print(orig_labels[3])\n",
        "ax4 = fig.add_subplot(2,2,4)\n",
        "ax4.imshow(images[4])\n",
        "print(orig_labels[4])"
      ],
      "metadata": {
        "id": "KQfcpgA3N2RZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}